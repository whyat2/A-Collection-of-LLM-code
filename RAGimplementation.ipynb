{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain_google_vertexai google-cloud-aplatform\n",
    "import dotenv\n",
    "import os\n",
    "from google.cloud import aiplatform\n",
    "from langchain_google_vertexai import (VertexAIEmbeddings, \n",
    "                VectorSearchVectorStore, VectorSearchVectorStoreDatastore, VertexAI)\n",
    "from langchain.prompts.chat import (ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate)\n",
    "from langchain_core.prompts.string import StringPromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load environment vars\n",
    "dotenv.load_dotenv()\n",
    "ProjectId = os.getenv('GOOGLE_VERTEX_PROJECT')\n",
    "Region = os.getenv('REGION_GOOGLE')\n",
    "Bucket = os.getenv('BUCKET_GOOGLE')\n",
    "BucketURI = f\"gs://{Bucket}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/158741848249/locations/us-central1/indexes/1901253516517703680/operations/4608412119476469760\n",
      "MatchingEngineIndex created. Resource name: projects/158741848249/locations/us-central1/indexes/1901253516517703680\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/158741848249/locations/us-central1/indexes/1901253516517703680')\n",
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/158741848249/locations/us-central1/indexEndpoints/7922935654218989568/operations/4969825989572952064\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/158741848249/locations/us-central1/indexEndpoints/7922935654218989568\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/158741848249/locations/us-central1/indexEndpoints/7922935654218989568')\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/158741848249/locations/us-central1/indexEndpoints/7922935654218989568\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/158741848249/locations/us-central1/indexEndpoints/7922935654218989568/operations/837562225227988992\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/158741848249/locations/us-central1/indexEndpoints/7922935654218989568\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=ProjectId, location=Region, staging_bucket=BucketURI)\n",
    "#setup the endpoint\n",
    "indexID = os.getenv('INDEXID_GOOGLE')\n",
    "endpointID = os.getenv('ENPOINTID_GOOGLE')\n",
    "if indexID == None or endpointID == None:\n",
    "    displayName = \"IndexSecure\" + (str)(random.randint(100000, 999999))\n",
    "    index = aiplatform.MatchingEngineIndex.create_tree_ah_index(display_name=displayName, dimensions=768,\n",
    "                                                        approximate_neighbors_count=150,\n",
    "                                                        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "                                                        index_update_method=\"STREAM_UPDATE\")\n",
    "    endpoint = aiplatform.MatchingEngineIndexEndpoint.create(display_name=f\"{displayName}-endpoint\", public_endpoint_enabled=True)\n",
    "    endpoint = endpoint.deploy_index(index = index, deployed_index_id=\"DeployedIndex03\")\n",
    "\n",
    "    indexID = endpoint.deployed_indexes[-1].index.split(\"/\")[-1]\n",
    "    endpointID = endpoint.name\n",
    "    os.environ['INDEXID_GOOGLE'] = indexID\n",
    "    os.environ['ENDPOINTID_GOOGLE'] = endpointID\n",
    "    dotenv.set_key(dotenv_path='.env', key_to_set='INDEXID_GOOGLE', value_to_set=indexID)\n",
    "    dotenv.set_key(dotenv_path='.env', key_to_set='ENDPOINTID_GOOGLE', value_to_set=endpointID)\n",
    "else:\n",
    "    index = aiplatform.MatchingEngineIndex(indexID)\n",
    "    enpoint = aiplatform.MatchingEngineIndexEndpoint(endpointID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"DeployedIndex01\"\n",
      "index: \"projects/158741848249/locations/us-central1/indexes/6023173075468550144\"\n",
      "create_time {\n",
      "  seconds: 1733023363\n",
      "  nanos: 390938000\n",
      "}\n",
      "index_sync_time {\n",
      "  seconds: 1733024885\n",
      "  nanos: 156626000\n",
      "}\n",
      "automatic_resources {\n",
      "  min_replica_count: 2\n",
      "  max_replica_count: 2\n",
      "}\n",
      "deployment_group: \"default\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'ENDPOINTID_GOOGLE', '1159707690373480448')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#indexID = endpoint.deployed_indexes[-1]\n",
    "#print(indexID)\n",
    "indexID = endpoint.deployed_indexes[-1].index.split(\"/\")[-1]\n",
    "endpointID = endpoint.name\n",
    "os.environ['INDEXID_GOOGLE'] = indexID\n",
    "os.environ['ENDPOINTID_GOOGLE'] = endpointID\n",
    "dotenv.set_key(dotenv_path='.env', key_to_set='INDEXID_GOOGLE', value_to_set=indexID)\n",
    "dotenv.set_key(dotenv_path='.env', key_to_set='ENDPOINTID_GOOGLE', value_to_set=endpointID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6023173075468550144\n"
     ]
    }
   ],
   "source": [
    "#indexID=endpoint.deployed_indexes[-1].index.split(\"/\")[-1]\n",
    "#print(indexID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingModel = VertexAIEmbeddings(model_name='textembedding-gecko@003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorStorage = VectorSearchVectorStore.from_components(project_id=ProjectId, region=Region, gcs_bucket_name=Bucket,\n",
    "                                                        index_id=indexID, endpoint_id=endpointID, embedding=embeddingModel, stream_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting datapoints MatchingEngineIndex index: projects/158741848249/locations/us-central1/indexes/1901253516517703680\n",
      "MatchingEngineIndex index Upserted datapoints. Resource name: projects/158741848249/locations/us-central1/indexes/1901253516517703680\n"
     ]
    }
   ],
   "source": [
    "textToSearch = [\n",
    "    \"John really likes his pizza\",\n",
    "    \"The sky is blue\",\n",
    "    \"John's pizza is a circle\",\n",
    "    \"John has severe issues\",\n",
    "    \"John needs to escape the horrible situtation he is in\",\n",
    "    \"John must run until he can escape\",\n",
    "    \"Spiralling spiralling spiralling\",\n",
    "    \"Oh look a squirell\",\n",
    "    \"John dies a brutal death none could have foreseen\",\n",
    "    \"Water is important to drink make sure you get enough\"\n",
    "]\n",
    "vectorStorage.add_texts(texts=textToSearch)\n",
    "\n",
    "vectorRetrieve = vectorStorage.as_retriever()\n",
    "vectorRetrieve.search_kwargs = {'k': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTemplate = \"\"\"You are an AI assistant given data from documents.\n",
    "    Answer questions using information provided.\n",
    "    Do not attempt to make up data you have not been given.\n",
    "    Simply state \"I don't know\" if you don't know the answer.\n",
    "    {summaries}\"\"\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(template=promptTemplate)\n",
    "\n",
    "human_message = HumanMessagePromptTemplate.from_template(template=\"{question}\")\n",
    "\n",
    "messages = [\n",
    "    system_message,\n",
    "    human_message\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "languageModel = VertexAI(model_name=\"gemini-1.5-flash\")\n",
    "chain = RetrievalQA.from_chain_type(llm=languageModel, chain_type='stuff', retriever=vectorRetrieve, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wyatt\\AppData\\Local\\Temp\\ipykernel_24976\\506884518.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "    What is the shape of John's pizza?\n",
      "    Answer: \n",
      "    A circle. \n",
      "\n",
      "    Source:\n",
      "    John's pizza is a circle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the shape of John's pizza?\"\n",
    "result = chain(query)\n",
    "output_text=f\"\"\"Question: \n",
    "    {query}\n",
    "    Answer: \n",
    "    {result['result']}\n",
    "    Source:\n",
    "    {' '.join(list(set([doc.page_content for doc in result['source_documents']])))}\n",
    "\"\"\"\n",
    "\n",
    "print(output_text)\n",
    "#make sure to go into vertex and close the things to avoid spending money on accident"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
